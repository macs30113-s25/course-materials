{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's Lab Agenda: \n",
    "\n",
    "1. cd to labs/week_5\n",
    "2. connect to AWS using terminal \n",
    "3. set up DynamoDB\n",
    "4. create Lambda Funtion to solve a problem\n",
    "5. hints for the Assignment5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AWS: \n",
    "\n",
    "1. start AWS lab   \n",
    "2. Terminal Command:   \n",
    "cd ~/.aws/  \n",
    "3. Change credential:   \n",
    "cat >credentials  (or use nano if you like)\n",
    "4. Control^D to exit  \n",
    "\n",
    "Boto3 would work now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up DynamoDB\n",
    "\n",
    "- DynamoDB is a fully managed NoSQL database service provided by AWS  \n",
    "  \n",
    "Let's create a DynamoDB table to collect and stream Twitter (now X) data in our database. \n",
    "\n",
    "- create Dynamo DB \n",
    "- put_item()\n",
    "- get_item()\n",
    "- update_item()\n",
    "- delete_item()\n",
    "\n",
    "- In order to find the item, each items needs a primary key. (1.partition key 2. partition key + sort key)\n",
    "We'll use Twitter 'username' as our primary key here, since this will be unique to each user and will make for a good input for DynamoDB's hash function (you can also specify a sort key if you would like, though).\n",
    "\n",
    "** We'll also set our Read and Write Capacity down to the minimum for this demo, but you can [scale this up](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html) if you need more throughput for your application (just be careful, as increasing your Read/Write Capacity too far will rapidly deplete your AWS credits). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Instantiate clients\n",
    "aws_lambda = boto3.client('lambda')\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='LabRole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2025-04-24 18:19:38.217000-05:00\n"
     ]
    }
   ],
   "source": [
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.create_table(\n",
    "    TableName='twitter',\n",
    "    KeySchema=[\n",
    "        {\n",
    "            'AttributeName': 'username',\n",
    "            'KeyType': 'HASH'\n",
    "        }\n",
    "    ],\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            'AttributeName': 'username',\n",
    "            'AttributeType': 'S'\n",
    "        }\n",
    "    ],\n",
    "    ProvisionedThroughput={\n",
    "        'ReadCapacityUnits': 1,\n",
    "        'WriteCapacityUnits': 1\n",
    "    }\n",
    ")\n",
    "\n",
    "# Wait until AWS confirms that table exists before moving on\n",
    "table.meta.client.get_waiter('table_exists').wait(TableName='twitter')\n",
    "\n",
    "# get data about table (should currently be no items in table)\n",
    "print(table.item_count)\n",
    "print(table.creation_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we currently have an empty DynamoDB table. Let's actually put some items into our table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'E8L6J1CI38M6QHPN8QJQVIFENNVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Thu, 24 Apr 2025 23:19:58 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'E8L6J1CI38M6QHPN8QJQVIFENNVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '2745614147'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.put_item(\n",
    "   Item={\n",
    "        'username': 'macs30113',\n",
    "        'num_followers': 100,\n",
    "        'num_tweets': 5\n",
    "    }\n",
    ")\n",
    "\n",
    "table.put_item(\n",
    "   Item={\n",
    "        'username': 'jon_c',\n",
    "        'num_followers': 10,\n",
    "        'num_tweets': 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily get items from our table using the `get_item` method and providing our key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_tweets': Decimal('5'), 'num_followers': Decimal('100'), 'username': 'macs30113'}\n"
     ]
    }
   ],
   "source": [
    "# try to retrive an item you just added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also update existing items using the `update_item` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'MI4AJJ2G7OMN7NTTKST9KVBF5BVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Thu, 24 Apr 2025 23:19:58 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'MI4AJJ2G7OMN7NTTKST9KVBF5BVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '2745614147'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update an value in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if we take a look again at this item, we'll see that it's been updated (note, though, that DynamoDB tables are [*eventually consistent* unless we specify otherwise](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html), so this might not always return the expected result immediately):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_followers': Decimal('100'), 'num_tweets': Decimal('6'), 'username': 'macs30113'}\n"
     ]
    }
   ],
   "source": [
    "# check the value of the item you just updated\n",
    "response = table.get_item(\n",
    "    Key={\n",
    "        'username': 'your_key\n",
    "    }\n",
    ")\n",
    "item = response['Item']\n",
    "print(item) # num_tweets should now be 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lambda Function for this case: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposed we wanted to gather data, perform pre-processing steps, and then enter into our database -- all in the cloud. To do this, we can use `boto3` to access our DynamoDB database from within other AWS resources (such as Lambda or EC2). For instance, let's create a Lambda function that will process some data (username, as well raw follower and tweet data) and enter the results of this processing into our database without ever leaving the AWS cloud (see zipped Lambda deployment package in this directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Lambda client\n",
    "aws_lambda = boto3.client('lambda')\n",
    "\n",
    "# Access our class IAM role, which allows Lambda\n",
    "# to interact with other AWS resources\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='LabRole')\n",
    "\n",
    "# Open our Zipped directory\n",
    "with open('write_to_dynamodb.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='your_own_name', # whatever you like as long as you use the same name later \n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda_function.lambda_handler', # Name of the file (lambda_function) and function(lambda_handler)\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=3\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "    FunctionName='your_own_name',\n",
    "    ZipFile=lambda_zip\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'StatusCode': 200}\n"
     ]
    }
   ],
   "source": [
    "# try to use your lambda function to dump to the table\n",
    "import json\n",
    "user1 = {\n",
    "        \"username\": \"jake_1\",\n",
    "        \"followers\": [\"sally\", \"jim\", \"jane\"],\n",
    "        \"tweets\": [\"this is fun!\", \"Let's tweet some more.\"]\n",
    "    }\n",
    "import json\n",
    "## invoke the lambda function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_tweets': Decimal('2'), 'num_followers': Decimal('3'), 'username': 'jake_'}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve item by primary key\n",
    "response = table.get_item(\n",
    "    Key={'username': 'jake_1'}\n",
    ")\n",
    "item = response['Item']\n",
    "print(item) # num_tweets should now be 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints for the Assignment5 \n",
    "- The workflow is to set up a Lambda function that processes survey submissions by storing the raw JSON payload in an S3 data lake and updating participant records in DynamoDB. \n",
    "- this data pipeline can automatically stores and organizes user-submitted survey dataâ€”raw inputs. S3 is used for long-term storage and auditing, while structured summaries are stored in DynamoDB for fast querying and analysis.\n",
    "- This structure enables efficient data management and real-time feedback without managing infrastructure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up S3 bucket\n",
    "\n",
    "s3 = boto3.client('s3') \n",
    "## pay attention here: if you want to put items into your bucket, \n",
    "## you need to use the s3 client, not the resource\n",
    "\n",
    "bucket = 'your-bucket-name' # replace with your bucket name \n",
    "s3.create_bucket(Bucket=bucket)\n",
    "print(\"S3 Bucket created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'EMYY92CCQSJB52EF',\n",
       "  'HostId': 'Et1AItBR23BkVWbrfEhebsCsUOJfxO5HS8pPMrL5t/U4UVK8cA6pUcukWFkehgkVplb3g7XvCV8=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Et1AItBR23BkVWbrfEhebsCsUOJfxO5HS8pPMrL5t/U4UVK8cA6pUcukWFkehgkVplb3g7XvCV8=',\n",
       "   'x-amz-request-id': 'EMYY92CCQSJB52EF',\n",
       "   'date': 'Thu, 24 Apr 2025 23:20:01 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"944697dde17e63dab300164aa70eb2a9\"',\n",
       "   'x-amz-checksum-crc64nvme': 'PXpC8YsKK6M=',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"944697dde17e63dab300164aa70eb2a9\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tweet data\n",
    "tweet_data = {\n",
    "    \"username\": \"joe_bloggs\",\n",
    "    \"followers\": [\"lily\", \"jim\", \"susan\", \"bob\"],\n",
    "    \"tweets\": [\"hello\"]\n",
    "}\n",
    "\n",
    "key = \"tweets/joe_bloggs.json\" # S3 key (path) for the objec\n",
    "s3.put_object(Body=json.dumps(tweet_data), Bucket=bucket, Key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects in bucket:\n",
      " - tweets/joe_bloggs.json\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3') # need to use resource to list objects\n",
    "print(\"Objects in bucket:\")\n",
    "bucket = s3.Bucket('twitter-123')\n",
    "for obj in bucket.objects.all():\n",
    "    print(\" -\", obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Finally, you should make sure to delete your table (if you no longer plan to use it), so that you do not incur further charges while it is running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TableDescription': {'TableName': 'twitter',\n",
       "  'TableStatus': 'DELETING',\n",
       "  'ProvisionedThroughput': {'NumberOfDecreasesToday': 0,\n",
       "   'ReadCapacityUnits': 1,\n",
       "   'WriteCapacityUnits': 1},\n",
       "  'TableSizeBytes': 0,\n",
       "  'ItemCount': 0,\n",
       "  'TableArn': 'arn:aws:dynamodb:us-east-1:211125736120:table/twitter',\n",
       "  'TableId': '90623826-7072-478f-af83-de9a089acecb',\n",
       "  'DeletionProtectionEnabled': False},\n",
       " 'ResponseMetadata': {'RequestId': 'I63VI3MOHL8UU8CJ8EGHG1BG1NVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'server': 'Server',\n",
       "   'date': 'Thu, 24 Apr 2025 23:20:01 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '350',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'I63VI3MOHL8UU8CJ8EGHG1BG1NVV4KQNSO5AEMVJF66Q9ASUAAJG',\n",
       "   'x-amz-crc32': '3834480598'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda Function Deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete Lambda if it still exists:\n",
    "try:\n",
    "    aws_lambda.delete_function(FunctionName='write_to_dynamodb')\n",
    "    print(\"Lambda Function Deleted\")\n",
    "except aws_lambda.exceptions.ResourceNotFoundException:\n",
    "    print(\"AWS Lambda Function Already Deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket Deleted\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket = \"your_bucket_name\" # replace with your bucket name\n",
    "# S3 -- note you only need to delete objects, not entire bucket in your final assignment\n",
    "try:\n",
    "    response = s3.list_objects(Bucket=bucket)\n",
    "    if 'Contents' in response:\n",
    "        for item in response['Contents']:\n",
    "            s3.delete_object(Bucket=bucket, Key=item['Key'])\n",
    "    s3.delete_bucket(Bucket=bucket)\n",
    "    print(\"S3 Bucket Deleted\")\n",
    "except s3.exceptions.NoSuchBucket:\n",
    "    print(\"S3 Bucket Already Deleted\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "macs30123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
